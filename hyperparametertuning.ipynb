{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('Churn_Modelling.csv')\n",
    "data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "label_encoder_gender = LabelEncoder()\n",
    "data['Gender'] = label_encoder_gender.fit_transform(data['Gender'])\n",
    "\n",
    "onehot_encoder_geo = OneHotEncoder(handle_unknown='ignore')\n",
    "geo_encoded = onehot_encoder_geo.fit_transform(data[['Geography']]).toarray()\n",
    "geo_encoded_df = pd.DataFrame(geo_encoded, columns=onehot_encoder_geo.get_feature_names_out(['Geography']))\n",
    "\n",
    "data = pd.concat([data.drop('Geography', axis=1), geo_encoded_df], axis=1)\n",
    "\n",
    "X = data.drop('Exited', axis=1)\n",
    "y = data['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Save encoders and scaler for later use\n",
    "with open('label_encoder_gender.pkl', 'wb') as file:\n",
    "    pickle.dump(label_encoder_gender, file)\n",
    "\n",
    "with open('onehot_encoder_geo.pkl', 'wb') as file:\n",
    "    pickle.dump(onehot_encoder_geo, file)\n",
    "\n",
    "with open('scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a function to create the model and try different parameters(KerasClassifier)\n",
    "\n",
    "def create_model(neurons=32,layers=1):\n",
    "    model=Sequential()\n",
    "    model.add(Dense(neurons,activation='relu',input_shape=(X_train.shape[1],)))\n",
    "\n",
    "    for _ in range(layers-1):\n",
    "        model.add(Dense(neurons,activation='relu'))\n",
    "\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikeras in c:\\users\\priyanshu deora\\desktop\\project\\deep learning\\annclssification\\venv\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\priyanshu deora\\desktop\\project\\deep learning\\annclssification\\venv\\lib\\site-packages (from scikeras) (3.12.0)\n",
      "Requirement already satisfied: scikit-learn>=1.4.2 in c:\\users\\priyanshu deora\\desktop\\project\\deep learning\\annclssification\\venv\\lib\\site-packages (from scikeras) (1.7.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\priyanshu deora\\desktop\\project\\deep learning\\annclssification\\venv\\lib\\site-packages (from keras>=3.2.0->scikeras) (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\priyanshu deora\\desktop\\project\\deep learning\\annclssification\\venv\\lib\\site-packages (from keras>=3.2.0->scikeras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\priyanshu deora\\desktop\\project\\deep learning\\annclssification\\venv\\lib\\site-packages (from keras>=3.2.0->scikeras) (14.2.0)\n",
      "Requirement already satisfied: namex in c:\\users\\priyanshu deora\\desktop\\project\\deep learning\\annclssification\\venv\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.1.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\priyanshu deora\\desktop\\project\\deep learning\\annclssification\\venv\\lib\\site-packages (from keras>=3.2.0->scikeras) (3.15.1)\n",
      "Requirement already satisfied: optree in c:\\users\\priyanshu deora\\desktop\\project\\deep learning\\annclssification\\venv\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.18.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\priyanshu deora\\desktop\\project\\deep learning\\annclssification\\venv\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\priyanshu deora\\desktop\\project\\deep learning\\annclssification\\venv\\lib\\site-packages (from keras>=3.2.0->scikeras) (25.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\priyanshu deora\\desktop\\project\\deep learning\\annclssification\\venv\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\priyanshu deora\\desktop\\project\\deep learning\\annclssification\\venv\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\priyanshu deora\\desktop\\project\\deep learning\\annclssification\\venv\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\priyanshu deora\\desktop\\project\\deep learning\\annclssification\\venv\\lib\\site-packages (from optree->keras>=3.2.0->scikeras) (4.15.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\priyanshu deora\\desktop\\project\\deep learning\\annclssification\\venv\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\priyanshu deora\\desktop\\project\\deep learning\\annclssification\\venv\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\priyanshu deora\\desktop\\project\\deep learning\\annclssification\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikeras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# make sure input_dim is defined e.g. input_dim = X.shape[1]\n",
    "def build_model(neurons=32, layers=1, input_dim=None):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=input_dim, activation='relu'))\n",
    "    for _ in range(layers - 1):\n",
    "        model.add(Dense(neurons, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Note: pass model=build_model (SciKeras uses 'model' arg)\n",
    "clf = KerasClassifier(model=build_model, verbose=0)\n",
    "\n",
    "# Route model-building args with model__ prefix, fit args with fit__ prefix\n",
    "param_grid = {\n",
    "    'model__neurons': [16, 32, 64, 128],\n",
    "    'model__layers': [1, 2],\n",
    "    'fit__epochs': [50, 100,500],\n",
    "    # you can also tune batch_size via fit__batch_size or set it in KerasClassifier(...)\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=clf, param_grid=param_grid, n_jobs=-1, cv=3, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a Keras classifier\n",
    "model=KerasClassifier(layers=1,neurons=32,build_fn=create_model,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the grid search parameters\n",
    "param_grid = {\n",
    "    'neurons': [16, 32, 64, 128],\n",
    "    'layers': [1, 2],\n",
    "    'epochs': [50, 100,500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "Best Score:  0.8571235891087507\n",
      "Best Params: {'fit__epochs': 500, 'model__layers': 1, 'model__neurons': 16}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "# 1. Update function to accept 'meta'\n",
    "def create_model(neurons=32, layers=1, meta=None):\n",
    "    # 2. Get input features from SciKeras metadata\n",
    "    # This automatically detects X_train.shape[1]\n",
    "    n_features_in_ = meta[\"n_features_in_\"]\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    # 3. Use an explicit Input Layer\n",
    "    # This forces Keras 3 to build the graph immediately, fixing the AttributeError\n",
    "    model.add(Input(shape=(n_features_in_,)))\n",
    "    \n",
    "    # First hidden layer (no input_dim needed here anymore)\n",
    "    model.add(Dense(neurons, activation='relu'))\n",
    "    \n",
    "    # Additional layers\n",
    "    for _ in range(layers - 1):\n",
    "        model.add(Dense(neurons, activation='relu'))\n",
    "        \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap model\n",
    "# We do not need to pass input_shape manually here; SciKeras handles it via 'meta'\n",
    "model = KerasClassifier(model=create_model, verbose=0)\n",
    "\n",
    "param_grid = {\n",
    "    'model__neurons': [16, 32, 64, 128],\n",
    "    'model__layers': [1, 2],\n",
    "    'fit__epochs': [50, 100, 500]\n",
    "}\n",
    "\n",
    "# Ensure data is numpy array and y is the correct shape\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "\n",
    "# Run Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Score: \", grid_result.best_score_)\n",
    "print(\"Best Params:\", grid_result.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
